{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Competition/Dataset : TMDB Box Office Prediction\n* DATE : 2021/01/24\n\n이 notebook은 다음의 notebook을 참고하여 공부한 것 입니다. \n* Link : https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation"},{"metadata":{},"cell_type":"markdown","source":"# Part 0. 문제 정의 \n\n\n**TMDB Box Office Prediction**은 과거에 상영된 영화 데이터를 이용하여 영화 수익을 예측해보는 대회이다. \n\n영화별 각 ID에 대한 수익 예측 값을 제출해야 한다. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split, KFold\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nimport json\nimport ast\nimport eli5\nimport shap\nfrom catboost import CatBoostRegressor\nfrom urllib.request import urlopen\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 1. Data loading and overview"},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Data set 불러오기"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train data와 test data를 살펴보면 총 21개의 features와 target value인 'revenue'가 있음을 알 수 있다. \n\n각각의 feature들이 의미하는 바는 다음과 같다. \n\n* 'id' : 각 영화의 고유 id 값\n* 'belongs_to_collection' : TMDB ID, 이름, 영화 포스터 및 영화 URL이 JSON 형식으로 담겨져 있음\n* 'budget' : 영화 예산, 달러로 표시. (단, 값을 알 수 없는 경우엔 0으로 표기)\n* 'genres' : 장르 이름과 TMDB ID가 JSON 형식으로 담겨져 있음\n* 'homepage' : 공식 홈페이지 URL\n* 'imdb_id' : 영화의 IMDB ID(string 형식)\n* 'original_language' : 두개의 문자로 표기된 영화 제작 언어\n* 'original_title' : 영화의 원래 제목\n* 'overview' : 영화에 대한 간단한 기술\n* 'popularity' : 영화의 인기도\n* 'poster_path' : 영화 포스터 주소\n* 'production_companies' : 영화 제작사의 이름과 TMDB ID가 JSON 형식으로 저장\n* 'production_countries' : 영화 제작 국가의 이름이 JSON 형식으로 저장\n* 'release_date' : 영화 개봉일 (mm/dd/yy 형식)\n* 'runtime' : 영화 상영시간\n* 'status' : 개봉 여부\n* 'tagline' : 영화의 tagline\n* 'title' : 영화의 영어 제목\n* 'Keywords' : TMDB ID와 모든 키워드가 JSON 형식으로 저장\n* 'cast' : 모든 출연진의 TMDB ID, 이름, 캐릭터 이름, 성별이 JSON 형식으로 저장\n* 'crew' : 제작과 관련된 인물들의 이름, TMDB ID, 프로필 주소\n* 'revenue' : 영화 수익(달러 기준)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**딕셔너리** 형태로 담겨져 있는 feature가 존재함을 알 수 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n    return df\n\ntrain = text_to_dict(train)\ntest = text_to_dict(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"앞서 대회의 dataset 설명을 보면 JSON 형식으로 저장된 feature들이 있다. 이것들을 읽어서 python 변수로 만들기 위해 **ast.literal_eval()** 을 사용한다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train set에 3000개의 samples이 있다. 이정도면 학습하기에 충분하다고 한다. \n또한 train set에선 feature의 개수가 23개인 반면 test set에선 22개인 이유는 우리의 예측 목표인 target variable의 유무 때문이다."},{"metadata":{},"cell_type":"markdown","source":"---\n## Data Overview\n## 1.2 belongs_to_collection"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['belongs_to_collection'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing value가 무려 2396개나 있는 것을 볼 수 있다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\ntrain['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n\ntest['collection_name'] = test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\ntest['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n\ntrain = train.drop(['belongs_to_collection'], axis=1)\ntest = test.drop(['belongs_to_collection'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`belongs_to_collection` 에 속해 있는 `name`과 collection의 유무에 관한 변수를 만든다. 다른 속성들은 이미지 주소값이기에 불필요하다. "},{"metadata":{},"cell_type":"markdown","source":"## 1.3 genres"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['genres'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`genres`가 1가지인 경우도 있지만 여러개인 경우도 존재한다. 그렇다면 각 sample 별로 `genres`가 총 몇 개인지 세어볼 필요가 있을 것 같다."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of genres in films')\ntrain['genres'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`genres`가 2~3개인 경우가 가장 많고 특이한 점은 `genres`가 0개인 경우가 존재한다는 것이다. 이것을 결측값으로 봐야하는 지에 대한 고민이 든다. `genres`의 개수별로 통계를 내어보았으니 이젠 `genres`의 종류별로도 통계를 내볼 필요가 있을 것 같다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_genres = list(train['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\ntext = ' '.join([i for j in list_of_genres for i in j])\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                     width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top genres')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Drama**, **Comedy**, **Thriller**이 가장 대중적인 `genres`인 것으로 보인다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter([i for j in list_of_genres for i in j]).most_common()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_genres'] = train['genres'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_genres'] = train['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_genres = [m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(15)]\nfor g in top_genres:\n    train['genre_' + g] = train['all_genres'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_genres'] = test['genres'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_genres'] = test['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_genres:\n    test['genre_' + g] = test['all_genres'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['genres'], axis=1)\ntest = test.drop(['genres'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`genres` feature에 대해 one-hot-encoding을 적용하였다."},{"metadata":{},"cell_type":"markdown","source":"## 1.4 production_companies"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['production_companies'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"각 sample 별로 여러개의 `production_companies`가 존재하는 모습을 볼 수 있다. 따라서 몇개의 `production_companies`를 가지고 있는 지 나눠서 봐야할 것 같다."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of production companies in films')\ntrain['production_companies'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"보통 영화당 1-2개의 `production_companies`를 가지고 있으며 때때로 3-4개의 `production_companies`를 가지고 있는 모습을 볼 수 있다.\n \n드물지만 10개 이상의 `production_companies`를 가진 영화들도 있다. 이들은 어떤 영화들인 지 살펴보도록 하자."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['production_companies'].apply(lambda x: len(x) if x != {} else 0) > 11]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"이제 어떤 `production_companies`이 빈번하게 나타나는 지를 살펴볼 차례이다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_companies = list(train['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list_of_companies)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter([i for j in list_of_companies for i in j]).most_common(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_companies'] = train['production_companies'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_production_companies'] = train['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_companies = [m[0] for m in Counter([i for j in list_of_companies for i in j]).most_common(30)]\nfor g in top_companies:\n    train['production_company_' + g] = train['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n\ntest['num_companies'] = test['production_companies'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_production_companies'] = test['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_companies = [m[0] for m in Counter([i for j in list_of_companies for i in j]).most_common(30)]\nfor g in top_companies:\n    test['production_company_' + g] = test['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['production_companies', 'all_production_companies'], axis=1)\ntest = test.drop(['production_companies', 'all_production_companies'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.5 production_countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['production_countries'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`production_countries`에서도 한 sample 당 여러 개의 항목을 가지고 있는 지 확인해보자."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of production countries in films')\ntrain['production_countries'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"대부분 한 국가에서 제작되었지만 여러 국가들과 공동 제작한 영화들도 있다.\n어떤 국가에서 주로 제작되었는지 살펴보자!"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_countries = list(train['production_countries'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_countries for i in j]).most_common(25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"역시나 미국이 압도적으로 많다. 아까 `production_companies`에서 했던 작업을 그대로 해주도록 하자."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_countries'] = train['production_countries'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_countries'] = train['production_countries'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_countries = [m[0] for m in Counter([i for j in list_of_countries for i in j]).most_common(25)]\nfor g in top_countries:\n    train['production_country_' + g] = train['all_countries'].apply(lambda x: 1 if g in x else 0)\n\ntest['num_countries'] = test['production_countries'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_countries'] = test['production_countries'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_countries = [m[0] for m in Counter([i for j in list_of_countries for i in j]).most_common(25)]\nfor g in top_countries:\n    test['production_country_' + g] = test['all_countries'].apply(lambda x: 1 if g in x else 0)\n\n    \ntrain = train.drop(['production_countries', 'all_countries'], axis=1)\ntest = test.drop(['production_countries', 'all_countries'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.6 spoken_languages"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['spoken_languages'][:100]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of spoken languages in films')\ntrain['spoken_languages'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_languages = list(train['spoken_languages'].apply(lambda x: [i['iso_639_1'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_languages for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"아까와 비슷한 작업을 해주었고 역시나 영어가 가장 많이 사용되었음을 볼 수 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_languages'] = train['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_languages'] = train['spoken_languages'].apply(lambda x: ' '.join(sorted([i['iso_639_1'] for i in x])) if x != {} else '')\ntop_languages = [m[0] for m in Counter([i for j in list_of_languages for i in j]).most_common(30)]\nfor g in top_languages:\n    train['language_' + g] = train['all_languages'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_languages'] = test['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_languages'] = test['spoken_languages'].apply(lambda x: ' '.join(sorted([i['iso_639_1'] for i in x])) if x != {} else '')\nfor g in top_languages:\n    test['language_' + g] = test['all_languages'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['spoken_languages', 'all_languages'], axis=1)\ntest = test.drop(['spoken_languages', 'all_languages'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.7 Keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['Keywords'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of Keywords in films')\ntrain['Keywords'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Keywords` 수의 분포가 거의 엇비슷한 것 같다. 숫자로 유의미한 차이를 가져올 수 있을 지는 잘 모르겠다. 다만 중요하다면 어떤 키워드가 나오는 지가 더 중요할 것 같다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_keywords = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nplt.figure(figsize = (16 ,12))\ntext = ' '.join(['_'.join(i.split(' ')) for j in list_of_keywords for i in j])\nwordcloud = WordCloud(max_font_size=None,  background_color='black', collocations=False,\n                     width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top keywords')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_Keywords'] = train['Keywords'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_Keywords'] = train['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_keywords = [m[0] for m in Counter([i for j in list_of_keywords for i in j]).most_common(30)]\nfor g in top_keywords:\n    train['keyword_' + g] = train['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_Keywords'] = test['Keywords'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_Keywords'] = test['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_keywords:\n    test['keyword_' + g] = test['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['Keywords', 'all_Keywords'], axis=1)\ntest = test.drop(['Keywords', 'all_Keywords'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.8 cast"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['cast'][:1]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of casted persons in films')\ntrain['cast'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"등장 인물의 수도 중요할 수 있지만 그보다 훨씬 중요한 것은 '어떤 배우가 캐스팅 됐는 지'이다. 영화의 흥행에 많은 영향을 미칠 것이라고 생각이 든다. 배우별, 성별, 캐릭터에 따라 나눠볼 필요가 있을 것 같다."},{"metadata":{},"cell_type":"markdown","source":"### 1.8.1 name of casting"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_names = list(train['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_names for i in j]).most_common(15)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.8.2 gender of casting"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_genders = list(train['cast'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_genders for i in j]).most_common()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 0 : 명시되지 않은 값\n* 1 : 여성\n* 2 : 남성\n\n남성이 가장 많이 캐스팅 되는 것으로 보이지만 명시되지 않은 값인 0을 지닌 sample이 상당히 많기 때문에 단정지을 순 없을 것 같다. "},{"metadata":{},"cell_type":"markdown","source":"### 1.8.3 character of casting"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_characters = list(train['cast'].apply(lambda x: [i['character'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_characters for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_cast'] = train['cast'].apply(lambda x: len(x) if x != {} else 0)\ntop_cast_names = [m[0] for m in Counter([i for j in list_of_cast_names for i in j]).most_common(15)]\nfor g in top_cast_names:\n    train['cast_name_' + g] = train['cast'].apply(lambda x: 1 if g in str(x) else 0)\ntrain['genders_0_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntrain['genders_1_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntrain['genders_2_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\ntop_cast_characters = [m[0] for m in Counter([i for j in list_of_cast_characters for i in j]).most_common(15)]\nfor g in top_cast_characters:\n    train['cast_character_' + g] = train['cast'].apply(lambda x: 1 if g in str(x) else 0)\n    \ntest['num_cast'] = test['cast'].apply(lambda x: len(x) if x != {} else 0)\nfor g in top_cast_names:\n    test['cast_name_' + g] = test['cast'].apply(lambda x: 1 if g in str(x) else 0)\ntest['genders_0_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntest['genders_1_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntest['genders_2_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\nfor g in top_cast_characters:\n    test['cast_character_' + g] = test['cast'].apply(lambda x: 1 if g in str(x) else 0)\n\ntrain = train.drop(['cast'], axis=1)\ntest = test.drop(['cast'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.9 crew"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, en in enumerate(train['crew'][:1]):\n    print(i, e[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of casted persons in films')\ntrain['crew'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_names = list(train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_names for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_jobs = list(train['crew'].apply(lambda x: [i['job'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_jobs for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_genders = list(train['crew'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_genders for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_departments = list(train['crew'].apply(lambda x: [i['department'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_departments for i in j]).most_common(14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_crew'] = train['crew'].apply(lambda x: len(x) if x != {} else 0)\ntop_crew_names = [m[0] for m in Counter([i for j in list_of_crew_names for i in j]).most_common(15)]\nfor g in top_crew_names:\n    train['crew_name_' + g] = train['crew'].apply(lambda x: 1 if g in str(x) else 0)\ntrain['genders_0_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntrain['genders_1_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntrain['genders_2_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\ntop_crew_jobs = [m[0] for m in Counter([i for j in list_of_crew_jobs for i in j]).most_common(15)]\nfor j in top_crew_jobs:\n    train['jobs_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\ntop_crew_departments = [m[0] for m in Counter([i for j in list_of_crew_departments for i in j]).most_common(15)]\nfor j in top_crew_departments:\n    train['departments_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n    \ntest['num_crew'] = test['crew'].apply(lambda x: len(x) if x != {} else 0)\nfor g in top_crew_names:\n    test['crew_name_' + g] = test['crew'].apply(lambda x: 1 if g in str(x) else 0)\ntest['genders_0_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntest['genders_1_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntest['genders_2_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\nfor j in top_crew_jobs:\n    test['jobs_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\nfor j in top_crew_departments:\n    test['departments_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n\ntrain = train.drop(['crew'], axis=1)\ntest = test.drop(['crew'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2. Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Missing value 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum() / train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Train set에서는 'belongs_to_collection'에 약 80%, 'homepage'에 68%, 'tagline' 약 20%의 결측치가 존재한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum() / test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test set에서도 'belongs_to_collection'에 약 80%, 'homepage'에 68%, 'tagline' 약 20%의 결측치가 존재한다."},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Target value 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (16, 6))\nplt.subplot(1, 2, 1)\nplt.hist(train['revenue']);\nplt.title('Distribution of revenue');\nplt.subplot(1, 2, 2)\nplt.hist(np.log1p(train['revenue']));\nplt.title('Distribution of log of revenue');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target value인 'revenue'가 매우 skewed함으로 log를 씌워 관찰한다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['log_revenue'] = np.log1p(train['revenue'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Budget"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (16, 6))\nplt.subplot(1, 2, 1)\nplt.hist(train['budget']);\nplt.title('Distribution of budget');\nplt.subplot(1, 2, 2)\nplt.hist(np.log1p(train['budget']));\nplt.title('Distribution of log of budget');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.scatter(train['budget'], train['revenue'])\nplt.title('Revenue vs budget');\nplt.subplot(1, 2, 2)\nplt.scatter(np.log1p(train['budget']), train['log_revenue'])\nplt.title('Log Revenue vs log budget');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['log_budget'] = np.log1p(train['budget'])\ntest['log_budget'] = np.log1p(test['budget'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4 homepage"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['homepage'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"대부분의 `homepage`들이 unique함을 알 수 있다. 따라서 이 feature는 딱히 필요가 없을 것 같다."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['has_homepage'] = 0\ntrain.loc[train['homepage'].isnull() == False, 'has_homepage'] = 1\ntest['has_homepage'] = 0\ntest.loc[test['homepage'].isnull() == False, 'has_homepage'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='has_homepage', y='revenue', data=train);\nplt.title('Revenue for film with and without homepage');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"다만 `homepage`의 유무를 기준으로 따져보면 `homepage`를 가지고 있는 쪽이 더 큰 `revenue`값을 가지는 것을 확인할 수 있다."},{"metadata":{},"cell_type":"markdown","source":"## 2.5 original_title"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 12))\ntext = ' '.join(train['original_title'].values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top words in titles')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.6 overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 12))\ntext = ' '.join(train['overview'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top words in overview')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`revenue`에 가장 큰 영향을 주는 단어가 무엇인지 살펴보도록 하자. "},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(\n            sublinear_tf=True,\n            analyzer='word',\n            token_pattern=r'\\w{1,}',\n            ngram_range=(1,2),\n            min_df=5)\n\noverview_text = vectorizer.fit_transform(train['overview'].fillna(''))\nlinreg = LinearRegression()\nlinreg.fit(overview_text, train['log_revenue'])\neli5.show_weights(linreg, vec=vectorizer, top=20, feature_filter=lambda x: x != '<BIAS>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Target value:', train['log_revenue'][1000])\neli5.show_prediction(linreg, doc=train['overview'].values[1000], vec=vectorizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.7 popularity"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.scatter(train['popularity'], train['revenue'])\nplt.title('Revenue vs popularity');\nplt.subplot(1, 2, 2)\nplt.scatter(train['popularity'], train['log_revenue'])\nplt.title('Log Revenue vs popularity');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'popularity'와 'revenue'의 상관관계가 그리 뚜렷하지 않음을 볼 수 있다. "},{"metadata":{},"cell_type":"markdown","source":"\n## 2.8 release_date"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test['release_date'].isnull() == True, 'release_date'] = '01/01/98'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['release_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 두 자리로 표현된 년도를 4자리로 바꾸는 함수\n\ndef fix_date(x):\n    year = x.split('/')[2]\n    if int(year) <= 19:\n        return x[:-2] + '20' + year\n    else:\n        return x[:-2] + '19' + year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntest['release_date'] = pd.to_datetime(test['release_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_date(df):\n    date_parts = [\"year\", \"weekday\", \"month\", 'weekofyear', 'day', 'quarter']\n    for part in date_parts:\n        part_col = 'release_date' + \"_\" + part\n        df[part_col] = getattr(df['release_date'].dt, part).astype(int)\n        \n    return df\n\ntrain = process_date(train)\ntest = process_date(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = train['release_date_year'].value_counts().sort_index()\nd2 = test['release_date_year'].value_counts().sort_index()\ndata = [go.Scatter(x=d1.index, y=d1.values, name='train'), go.Scatter(x=d2.index, y=d2.values, name='test')]\nlayout = go.Layout(dict(title = \"Number of films per year\",\n                  xaxis = dict(title = 'Year'),\n                  yaxis = dict(title = 'Count'),\n                  ),legend=dict(\n                orientation=\"v\"))\npy.iplot(dict(data=data, layout=layout))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = train['release_date_year'].value_counts().sort_index()\nd2 = train.groupby(['release_date_year'])['revenue'].sum()\ndata = [go.Scatter(x=d1.index, y=d1.values, name='film count'), go.Scatter(x=d2.index, y=d2.values, name='total revenue', yaxis='y2')]\nlayout = go.Layout(dict(title = \"Number of films and total revenue per year\",\n                  xaxis = dict(title = 'Year'),\n                  yaxis = dict(title = 'Count'),\n                  yaxis2=dict(title='Total revenue', overlaying='y', side='right')\n                  ),legend=dict(\n                orientation=\"v\"))\npy.iplot(dict(data=data, layout=layout))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = train['release_date_year'].value_counts().sort_index()\nd2 = train.groupby(['release_date_year'])['revenue'].mean()\ndata = [go.Scatter(x=d1.index, y=d1.values, name='film count'), go.Scatter(x=d2.index, y=d2.values, name='mean revenue', yaxis='y2')]\nlayout = go.Layout(dict(title = \"Number of films and average revenue per year\",\n                  xaxis = dict(title = 'Year'),\n                  yaxis = dict(title = 'Count'),\n                  yaxis2=dict(title='Average revenue', overlaying='y', side='right')\n                  ),legend=dict(\n                orientation=\"v\"))\npy.iplot(dict(data=data, layout=layout))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"영화 작품의 수나 전체 `revenue`는 전반적으로 성장하는 모습을 보이고 있다. 하지만 평균`revenue`는 1970년대 후반과 같이 특정 성공한 작품이 존재했던 해에 큰 값을 보이는 모습을 볼 수 있다. 즉, 최신 작품이라고 해서 평균 `revenue`가 항상 높은 것은 아니라는 말이다. 다만 가장 최근에는 지금까지의 `revenue`를 뛰어넘는 모습을 볼 수 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='release_date_weekday', y='revenue', data=train);\nplt.title('Revenue on different days of week of release');\nloc, labels = plt.xticks()\nloc, labels = loc, [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\nplt.xticks(loc, labels, fontsize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"수요일에 가장 큰 `revenue`를 보여준다."},{"metadata":{},"cell_type":"markdown","source":"## 2.9 runtime"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,6))\nplt.subplot(1, 3, 1)\nplt.hist(train['runtime'].fillna(0)/60, bins=40);\nplt.title('Distribution of length of film in hours');\nplt.subplot(1, 3, 2)\nplt.scatter(train['runtime'].fillna(0), train['revenue'])\nplt.xlabel('runtime')\nplt.ylabel('revenue')\nplt.title('runtime vs revenue');\nplt.subplot(1, 3, 3)\nplt.scatter(train['runtime'].fillna(0), train['popularity'])\nplt.xlabel('runtime')\nplt.ylabel('popularity')\nplt.title('runtime vs popularity');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"보통 1.5-2시간의 `runtime`을 가지고 있는 영화가 `revenue`도 높고 `popularity`도 높은 편으로 나타난다."},{"metadata":{},"cell_type":"markdown","source":"## 2.10 status"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train에선 4개, test에선 오직 7개만이 개봉되지 않은 상태이다. 따라서 이 feature는 필요하지 않을 것 같다."},{"metadata":{},"cell_type":"markdown","source":"## 2.11 tagline"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 12))\ntext = ' '.join(train['tagline'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top words in tagline')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.11 collections"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='has_collection', y='revenue', data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Collection을 가진 영화가 좀 더 높은 `revenue`를 가지고 있다. 아무래도 어벤져스나 마블 시리즈처럼 성공한 시리즈물일수록 거대한 팬층이 형성되고 그것이 다시 새 시리즈 작품의 이윤 창출에 많은 영향을 주기 때문이라고 생각된다."},{"metadata":{},"cell_type":"markdown","source":"## 2.11 genres"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='num_genres', y='revenue', data=train);\nplt.title('Revenue for different number of genres in the film');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`genres`의 개수가 3개일 때 가장 높은 이윤을 보여주고 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x='genre_Drama', y='revenue', data=train[:100]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" 이전에 살펴봤을 때 drama가 가장 많이 나오는 `genres`였기 때문에 drama를 `genres`로 가지고 있을 때의 `revenue`를 살펴보았다. 하지만 생각과는 다르게 drama가 아닐 때 더 높은 `revenue`를 가진 영화가 존재하였다."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(24, 12))\nplt.suptitle('Violinplot of revenue vs genres')\nfor i, e in enumerate([col for col in train.columns if 'genre_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"몇몇 `genres`는 낮은 `revenue`를 보이고 몇몇 `genres`는 높은 것을 보아 `genres`도 나름 중요한 역할을 한다고 볼 수 있을 것 같다."},{"metadata":{},"cell_type":"markdown","source":"## 2.12 production companies"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(6, 5, figsize=(24, 32))\nplt.suptitle('Violinplot of revenue vs production company')\nfor i, e in enumerate([col for col in train.columns if 'production_company' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"소수의 회사들만이 다른 회사들보다 높은 `revenue`를 보이고 있다. "},{"metadata":{},"cell_type":"markdown","source":"## 2.13 production countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='num_countries', y='revenue', data=train)\nplt.title('Revenue for different number of countries producing the film');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`production_countries`의 개수가 1-2개일 때 가장 높은 `revenue`를 보여주지만 이는 대부분의 영화들이 1-2개의 `production_countries`를 가지고 있기 때문에 그렇다고 볼 수 있을 것 같다. 따라서 `production_countries`의 수는 그다지 중요하지 않을 것 같다."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(5, 5, figsize=(24, 32))\nplt.suptitle('Violinplot of revenue vs production country')\nfor i, e in enumerate([col for col in train.columns if 'production_country' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"미국과 일본정도만 다른 나라에 비해서 높은 `revenue`를 보여주고 있다."},{"metadata":{},"cell_type":"markdown","source":"## 2.14 cast"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 8))\nplt.subplot(1, 2, 1)\nplt.scatter(train['num_cast'], train['revenue'])\nplt.title('Number of cast members vs revenue');\nplt.ylabel('revenue');\nplt.subplot(1, 2, 2)\nplt.scatter(train['num_cast'], train['log_revenue'])\nplt.title('Log Revenue vs number of cast members');\nplt.ylabel('log_revenue');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`cast` member의 수와 `revenue`는 어느정도 비례관계에 있지만 `cast` member의 수가 대부분 0-40에 몰려있다는 점은 생각해봐야 할 것 같다."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(24, 18))\nplt.suptitle('Violinplot of revenue vs cast')\nfor i, e in enumerate([col for col in train.columns if 'cast_name' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(24, 18))\nplt.suptitle('Violinplot of revenue vs cast')\nfor i, e in enumerate([col for col in train.columns if 'cast_character_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.15 keyword"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(6, 5, figsize=(24, 32))\nplt.suptitle('Violinplot of revenue vs keyword')\nfor i, e in enumerate([col for col in train.columns if 'keyword_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.16 crew"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.scatter(train['num_crew'], train['revenue'])\nplt.title('Number of crew members vs revenue');\nplt.ylabel('revenue');\nplt.subplot(1, 2, 2)\nplt.scatter(train['num_crew'], train['log_revenue'])\nplt.title('Log Revenue vs number of crew members');\nplt.ylabel('log_revenue');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(24, 18))\nplt.suptitle('Violinplot of revenue vs jobs')\nfor i, e in enumerate([col for col in train.columns if 'jobs_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(뭔가 한눈에 잘 들어오지 않는다. 나중에 좀 표현 방식을 바꿔야겠다..)"},{"metadata":{},"cell_type":"markdown","source":"# Part3. Modelling and feature generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['homepage', 'imdb_id', 'poster_path', 'release_date', 'status', 'log_revenue'], axis=1)\ntest = test.drop(['homepage', 'imdb_id', 'poster_path', 'release_date', 'status'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    if train[col].nunique() == 1:\n        print(col)\n        train = train.drop([col], axis=1)\n        test = test.drop([col], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['original_language', 'collection_name', 'all_genres']:\n    le = LabelEncoder()\n    le.fit(list(train[col].fillna('')) + list(test[col].fillna('')))\n    train[col] = le.transform(train[col].fillna('').astype(str))\n    test[col] = le.transform(test[col].fillna('').astype(str))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_texts = train[['title', 'tagline', 'overview', 'original_title']]\ntest_texts = test[['title', 'tagline', 'overview', 'original_title']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['title', 'tagline', 'overview', 'original_title']:\n    train['len_' + col] = train[col].fillna('').apply(lambda x: len(str(x)))\n    train['words_' + col] = train[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n    train = train.drop(col, axis=1)\n    test['len_' + col] = test[col].fillna('').apply(lambda x: len(str(x)))\n    test['words_' + col] = test[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n    test = test.drop(col, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Text features를 각각의 갯수와 단어별로 나누어 저장한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# data fixes from https://www.kaggle.com/somang1418/happy-valentines-day-and-keep-kaggling-3\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'revenue'] = 6800000       # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntest.loc[test['id'] == 3889,'budget'] = 15000000       # Colossal\ntest.loc[test['id'] == 6733,'budget'] = 5000000        # The Big Sick\ntest.loc[test['id'] == 3197,'budget'] = 8000000        # High-Rise\ntest.loc[test['id'] == 6683,'budget'] = 50000000       # The Pink Panther 2\ntest.loc[test['id'] == 5704,'budget'] = 4300000        # French Connection II\ntest.loc[test['id'] == 6109,'budget'] = 281756         # Dogtooth\ntest.loc[test['id'] == 7242,'budget'] = 10000000       # Addams Family Values\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n\npower_six = train.id[train.budget > 1000][train.revenue < 100]\n\nfor k in power_six :\n    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['id', 'revenue'], axis=1)\ny = np.log1p(train['revenue'])\nX_test = test.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'num_leaves': 30,\n         'min_data_in_leaf': 20,\n         'objective': 'regression',\n         'max_depth': 5,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.2,\n         \"verbosity\": -1}\nmodel1 = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\nmodel1.fit(X_train, y_train, \n        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(model1, feature_filter=lambda x: x != '<BIAS>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fold = 10\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(X, X_test, y, params=None, folds=folds, model_type='lgb', plot_feature_importance=False, model=None):\n\n    oof = np.zeros(X.shape[0])\n    prediction = np.zeros(X_test.shape[0])\n    scores = []\n    feature_importance = pd.DataFrame()\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n        print('Fold', fold_n, 'started at', time.ctime())\n        if model_type == 'sklearn':\n            X_train, X_valid = X[train_index], X[valid_index]\n        else:\n            X_train, X_valid = X.values[train_index], X.values[valid_index]\n        y_train, y_valid = y[train_index], y[valid_index]\n        \n        if model_type == 'lgb':\n            model = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n            model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n                    verbose=1000, early_stopping_rounds=200)\n            \n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n            \n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n            y_pred_valid = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test.values), ntree_limit=model.best_ntree_limit)\n\n        if model_type == 'sklearn':\n            model = model\n            model.fit(X_train, y_train)\n            y_pred_valid = model.predict(X_valid).reshape(-1,)\n            score = mean_squared_error(y_valid, y_pred_valid)\n            \n            y_pred = model.predict(X_test)\n            \n        if model_type == 'cat':\n            model = CatBoostRegressor(iterations=20000,  eval_metric='RMSE', **params)\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n\n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test)\n        \n        oof[valid_index] = y_pred_valid.reshape(-1,)\n        scores.append(mean_squared_error(y_valid, y_pred_valid) ** 0.5)\n        \n        prediction += y_pred    \n        \n        if model_type == 'lgb':\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = X.columns\n            fold_importance[\"importance\"] = model.feature_importances_\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction /= n_fold\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    if model_type == 'lgb':\n        feature_importance[\"importance\"] /= n_fold\n        if plot_feature_importance:\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n        \n            return oof, prediction, feature_importance\n        return oof, prediction\n    \n    else:\n        return oof, prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'num_leaves': 30,\n         'min_data_in_leaf': 10,\n         'objective': 'regression',\n         'max_depth': 5,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.2,\n         \"verbosity\": -1}\noof_lgb, prediction_lgb, _ = train_model(X, X_test, y, params=params, model_type='lgb', plot_feature_importance=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 OOF features based on texts"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train_texts.columns:\n    vectorizer = TfidfVectorizer(\n                sublinear_tf=True,\n                analyzer='word',\n                token_pattern=r'\\w{1,}',\n                ngram_range=(1, 2),\n                min_df=10\n    )\n    vectorizer.fit(list(train_texts[col].fillna('')) + list(test_texts[col].fillna('')))\n    train_col_text = vectorizer.transform(train_texts[col].fillna(''))\n    test_col_text = vectorizer.transform(test_texts[col].fillna(''))\n    model = linear_model.RidgeCV(alphas=(0.01, 0.1, 1.0, 10.0, 100.0), scoring='neg_mean_squared_error', cv=folds)\n    oof_text, prediction_text = train_model(train_col_text, test_col_text, y, params=None, model_type='sklearn', model=model)\n    \n    X[col + '_oof'] = oof_text\n    X_test[col + '_oof'] = prediction_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}